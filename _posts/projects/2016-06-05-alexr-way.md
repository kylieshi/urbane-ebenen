---
layout: page
title:  "WAY  -   When Are you?"
subheadline: Visualisierung verpasster Begegnungen
teaser: Kann man Beziehungen über ein Reminder-System virtuell anregen?
header: no
show_meta: false
categories:
    - projects
image:
    title: WAY/GIT_TEASER_PHONES.jpg
    caption: WAY - Startscreen und Active Mode
author: Alexandra Rupp
---
Kann man Beziehungen zwischen Menschen, die in Reichweite voneinander wohnen und sich dennoch nicht häufig treffen können, virtuell anregen?
Regelmäßige physische Nähe zu anderen Menschen beeinflusst unser Gefühl von Nähe zueinander. Alternativ kann auch Kommunikation auf digitalem Wege eine Präsenz im Alltag erzeugen und diese physiche Nähe zu Teilen ersetzen. Nun stellt sich die Frage, ob man die große Assoziationsfähigkeit unseres Gehirns nutzen kann, um noch einen Schritt weiter zu abstrahieren:
Wenn wir mit Anderen interagieren, fügt unser Gehirn neue Informationen zu unseren bestehenden Vorstellungen ("Konzepten") von Personen und Gegebenheiten hinzu. Wenn wir uns an Situationen erinnern, ruft das die relevante Konzepte und deren zugeordneten Informationen wieder auf.
Kann man dieses reine Triggern des Konzeptes, welches wir von einer Person haben, als eine Art *einseitig ablaufende Kommunikation* betrachten und davon einen ähnlichen Effekt erwarten wie bei tatsächlicher physischer oder digitaler Anwesenheit?

<figure>
<img src="{{ site.urlimg }}WAY/WAY_virtualConnectionKleinCUT.jpg"/>
<figcaption >Sketch des Gesamtkonzepts: "Vitalization of Emotional Proximity".</figcaption>
</figure>







<figure>
<img src="{{ site.urlimg }}/WAY/WAY_screensKlein.png"/>
<figcaption>Vier Hauptansichten von WAY</figcaption>
</figure>




## Visualisierung
Als Smartphoneanwendung zeigt *WAY* ihren Nutzern, auf Basis ihrer zurückgelegten Strecken in Echtzeit an, sobald die Wege zweier Probanten sich kreuzen. Eine subtile Farbeinblendung visualisiert die Orientierung des gekreuzten Pfades, während eine Farb-Nutzer-Zuordnung erkennen lässt, um wessen Pfad es sich handelt. Automatisch werden wir an die Person erinnert, deren Weg wir gerade gekreuzt haben.

<figure>
  <img src="{{ site.urlimg }}/WAY/AnzeigeCasesMITTEL.jpg"/>
  <figcaption>Eine subtile Farbeinblendung zeigt die Orientierung des Pfades in Bezug auf die aktuelle Position und Ausrichtung des Nutzers an.</figcaption>
</figure>

Es gibt zwei Modi Way zu nutzen: 1. Im aktiven Modus, der uns ermöglicht unsere Umwelt auf Pfade zu *scannen*. [Durch die Kamera des Handys sehen wir unsere direkte Umgebung, während die farbigen Overlays weiterhin Pfade in der Nähe angeben.] 2. Der passive Modus, der uns, sobald wir die App verlassen und ggf. eine andere aufrufen, immernoch die Overlays anzeigt."


<figure>
<a href="{{ site.urlimg }}/heimwaerts/plakat_gross.jpg">
  <figcaption >Der Active Mode in Aktion</figcaption>
</figure>


## Bestehende Strukturen
Sowohl bei der Grundidee, die natürlichen Fähigkeiten des Gehirns so zu sagen als *Abkürzung* zu nutzen, als auch bei der Konzipierung von Funktionen und Details der App spielt der Rückgriff auf bereits bestehende Strukturen eine essentielle Rolle.
<figure>
<img src="{{ site.urlimg }}WAY/WAY_surfingAbilitiesKleinCUT.jpg"/>
  <figcaption ></figcaption>
</figure>



## Prozess
Zunächst sollte *WAY - When Are You?* sich auf Basis von Kartenviualisierungen mit dem Thema sich überschneidender Wegstrecken und vielleicht *knapp?* verpasster Treffen beschäftigen. Doch dann kam die Frage auf, ob man nicht die rückschauende Herangehensweise hinter sich lassen könnte um stattdessen zu versuchen den eigentlichen Moment des Geschehens zu gestalten.

 - Ein Schritt von der *analysierenden* Überblicksansicht zu reduzierten Echtzeitvisulaisierung die *aktiv Teil des Prozesses* wird




## Daten
WAY zeigt ausschnitthaft die Wegstrecken der Nutzer. Hierfür könnte man unter Umständen GPS-Daten nutzen, doch aktuell gibt es dabei noch die Schwierigkeit, dass die für Privatpersonen zugängliche Erfassung und Verwertung von GPS-Daten noch zu große Ungenauigkeiten aufweist um die Anwendung konzeptgetreu in die Realität zu holen.
Die Prototypen arbeiten daher mit fixierten Positionen und flexibler Orientierung.




## Prototypen
Ein Clickdummy und zwei Beispiele für Active und Passive Mode sind entstanden und für Chrome Version 30+ verfügbar.

[WAY - Prototyp Clickdummy](https://invis.io/JQ7WPQHNA#/172753754_FS_START)

[WAY - Passive Mode](https://burg-halle.de/st4354/WAY/protoHG.html)

[WAY - Active Mode](https://burg-halle.de/st4354/WAY/protoVID.html)
